#!/usr/bin/env python3
"""
Phase 1 å†…å­˜ç®¡ç†ä¼˜åŒ–éªŒè¯æµ‹è¯• - Linusé£æ ¼ç›´æ¥éªŒè¯

éªŒè¯å†…å®¹ï¼š
1. æ™ºèƒ½ç¼“å­˜å¤§å° - ç³»ç»Ÿå†…å­˜è‡ªé€‚åº”
2. æ”¹è¿›çš„LRUé©±é€ç­–ç•¥ - è®¿é—®æ¨¡å¼æ„ŸçŸ¥
3. å†…å­˜å‹åŠ›æ£€æµ‹å’Œç´§æ€¥æ¸…ç†
4. ç¼“å­˜ç»Ÿè®¡ç›‘æ§åŠŸèƒ½

ç›®æ ‡ï¼š
- å†…å­˜ä½¿ç”¨å‡å°‘50% (1000æ–‡ä»¶ < 100MB)
- ç¼“å­˜å‘½ä¸­ç‡ > 70%
- æ— å†…å­˜æ³„æ¼
"""

import time
import tempfile
import os
from pathlib import Path
from typing import List, Dict

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    psutil = None

from src.core.cache import OptimizedFileCache, get_file_cache, clear_global_cache, _calculate_smart_cache_size


def create_large_project_files(base_dir: str, count: int = 1000) -> List[str]:
    """åˆ›å»ºå¤§å‹é¡¹ç›®æ–‡ä»¶ - æ¨¡æ‹ŸçœŸå®é¡¹ç›®"""
    files = []
    base_path = Path(base_dir)

    # åˆ›å»ºä¸åŒç±»å‹çš„æ–‡ä»¶
    for i in range(count):
        # éšæœºæ–‡ä»¶å¤§å° - æ¨¡æ‹ŸçœŸå®é¡¹ç›®
        if i % 10 == 0:
            # 10% å¤§æ–‡ä»¶ (>10KB)
            line_count = 500
            complexity = "large"
        elif i % 3 == 0:
            # 30% ä¸­ç­‰æ–‡ä»¶ (1-10KB)
            line_count = 100
            complexity = "medium"
        else:
            # 60% å°æ–‡ä»¶ (<1KB)
            line_count = 20
            complexity = "small"

        file_path = base_path / f"src/module_{i//50}" / f"file_{i}_{complexity}.py"
        file_path.parent.mkdir(parents=True, exist_ok=True)

        content = f'''"""
File {i} - {complexity} complexity
Generated for Phase 1 memory optimization testing
"""

import os
import sys
from typing import Dict, List, Optional

class TestClass{i}:
    """Test class {i} for complexity {complexity}"""

    def __init__(self, value: int = {i}):
        self.value = value
        self.data = [{j} for j in range({i % 10 + 1})]

    def process_data(self, input_data: List[int]) -> Dict[str, int]:
        """Process input data and return statistics"""
        result = {{
            "count": len(input_data),
            "sum": sum(input_data),
            "max": max(input_data) if input_data else 0,
            "min": min(input_data) if input_data else 0,
        }}
        return result

    def complex_operation(self):
        """Complex operation for testing"""
        operations = []
        for x in range(self.value % 100):
            operations.append(x * 2 + self.value)
        return operations

def utility_function_{i}(param1: str, param2: int = {i}) -> str:
    """Utility function {i}"""
    return f"{{param1}}_{{param2}}_{{complexity}}"

# Constants and configuration
CONFIG_{i} = {{
    "enabled": True,
    "value": {i},
    "complexity": "{complexity}",
    "data": list(range({i % 20}))
}}

'''

        # æ ¹æ®å¤æ‚åº¦æ·»åŠ æ›´å¤šå†…å®¹
        for line_num in range(line_count - 40):  # å‡å»å·²æœ‰çš„40è¡Œ
            content += f"# Additional line {line_num} for {complexity} file {i}\n"

        file_path.write_text(content, encoding='utf-8')
        files.append(str(file_path))

    return files


def test_smart_cache_sizing():
    """æµ‹è¯•æ™ºèƒ½ç¼“å­˜å¤§å°è®¡ç®—"""
    print("ğŸ§  æµ‹è¯•æ™ºèƒ½ç¼“å­˜å¤§å°è®¡ç®—...")

    # è·å–è®¡ç®—ç»“æœ
    max_files, max_memory_mb = _calculate_smart_cache_size()

    # è·å–ç³»ç»Ÿå†…å­˜ä¿¡æ¯è¿›è¡ŒéªŒè¯
    memory = psutil.virtual_memory()
    total_memory_gb = memory.total / (1024 ** 3)

    print(f"   ç³»ç»Ÿå†…å­˜: {total_memory_gb:.1f}GB")
    print(f"   è®¡ç®—çš„ç¼“å­˜å¤§å°: {max_files} æ–‡ä»¶")
    print(f"   è®¡ç®—çš„å†…å­˜é™åˆ¶: {max_memory_mb}MB")

    # éªŒè¯è®¡ç®—é€»è¾‘
    expected_files = int(400 * total_memory_gb)
    expected_memory = int((memory.total * 0.2) / (1024 * 1024))

    # è€ƒè™‘å®‰å…¨èŒƒå›´
    assert 100 <= max_files <= 5000, f"æ–‡ä»¶æ•°é‡è¶…å‡ºå®‰å…¨èŒƒå›´: {max_files}"
    assert 50 <= max_memory_mb <= 2048, f"å†…å­˜é™åˆ¶è¶…å‡ºå®‰å…¨èŒƒå›´: {max_memory_mb}MB"

    print("âœ… æ™ºèƒ½ç¼“å­˜å¤§å°è®¡ç®—æµ‹è¯•é€šè¿‡!")
    return max_files, max_memory_mb


def test_memory_pressure_detection():
    """æµ‹è¯•å†…å­˜å‹åŠ›æ£€æµ‹å’Œç´§æ€¥æ¸…ç†"""
    print("\nâš ï¸ æµ‹è¯•å†…å­˜å‹åŠ›æ£€æµ‹...")

    # åˆ›å»ºæœ‰é™å†…å­˜çš„ç¼“å­˜
    cache = OptimizedFileCache(max_size=100, max_memory_mb=5)

    with tempfile.TemporaryDirectory() as temp_dir:
        # åˆ›å»ºè¶³å¤Ÿå¤šçš„æ–‡ä»¶æ¥è§¦å‘å†…å­˜å‹åŠ›
        test_files = create_large_project_files(temp_dir, 150)

        # è®°å½•åˆå§‹çŠ¶æ€
        initial_memory = psutil.virtual_memory().available

        # æ¨¡æ‹Ÿé«˜å†…å­˜ä½¿ç”¨
        print("   åŠ è½½å¤§é‡æ–‡ä»¶...")
        for i, file_path in enumerate(test_files):
            cache.get_file_lines(file_path)

            # æ¯20ä¸ªæ–‡ä»¶æ£€æŸ¥ä¸€æ¬¡
            if i % 20 == 0:
                stats = cache.get_cache_stats()
                print(f"   è¿›åº¦: {i+1}/150, ç¼“å­˜æ–‡ä»¶: {stats['file_count']}, å†…å­˜: {stats['memory_usage_mb']:.1f}MB")

        # è·å–æœ€ç»ˆç»Ÿè®¡
        final_stats = cache.get_cache_stats()

        print(f"   æœ€ç»ˆæ–‡ä»¶æ•°: {final_stats['file_count']}")
        print(f"   æœ€ç»ˆå†…å­˜ä½¿ç”¨: {final_stats['memory_usage_mb']:.2f}MB")
        print(f"   æ¸…ç†æ¬¡æ•°: {final_stats['cleanup_count']}")
        print(f"   å†…å­˜è­¦å‘Š: {final_stats['memory_warnings']}")
        print(f"   ç´§æ€¥æ¸…ç†: {final_stats['emergency_cleanups']}")

        # éªŒè¯å†…å­˜é™åˆ¶æœ‰æ•ˆ
        assert final_stats['memory_usage_mb'] <= 5.0, f"å†…å­˜é™åˆ¶å¤±æ•ˆ: {final_stats['memory_usage_mb']:.2f}MB"
        assert final_stats['file_count'] <= 100, f"æ–‡ä»¶æ•°é‡é™åˆ¶å¤±æ•ˆ: {final_stats['file_count']}"

        print("âœ… å†…å­˜å‹åŠ›æ£€æµ‹æµ‹è¯•é€šè¿‡!")
        return final_stats


def test_intelligent_lru_strategy():
    """æµ‹è¯•æ™ºèƒ½LRUé©±é€ç­–ç•¥"""
    print("\nğŸ§® æµ‹è¯•æ™ºèƒ½LRUé©±é€ç­–ç•¥...")

    cache = OptimizedFileCache(max_size=20, max_memory_mb=2)

    with tempfile.TemporaryDirectory() as temp_dir:
        test_files = create_large_project_files(temp_dir, 30)

        # ç¬¬ä¸€é˜¶æ®µ: æ­£å¸¸è®¿é—®
        print("   ç¬¬ä¸€é˜¶æ®µ: æ­£å¸¸åŠ è½½æ–‡ä»¶...")
        for file_path in test_files[:15]:
            cache.get_file_lines(file_path)

        # ç¬¬äºŒé˜¶æ®µ: åˆ›å»ºè®¿é—®æ¨¡å¼
        print("   ç¬¬äºŒé˜¶æ®µ: åˆ›å»ºè®¿é—®æ¨¡å¼...")
        # é«˜é¢‘è®¿é—®æŸäº›æ–‡ä»¶
        high_freq_files = test_files[:5]
        for _ in range(5):  # è®¿é—®5æ¬¡
            for file_path in high_freq_files:
                cache.get_file_lines(file_path)
                time.sleep(0.01)  # å°å»¶è¿Ÿæ¨¡æ‹ŸçœŸå®è®¿é—®

        # è§„å¾‹è®¿é—®æŸäº›æ–‡ä»¶
        pattern_files = test_files[5:8]
        for _ in range(3):
            for file_path in pattern_files:
                cache.get_file_lines(file_path)
                time.sleep(0.05)  # è§„å¾‹é—´éš”

        # ç¬¬ä¸‰é˜¶æ®µ: è§¦å‘LRUé©±é€
        print("   ç¬¬ä¸‰é˜¶æ®µ: è§¦å‘LRUé©±é€...")
        # æ·»åŠ æ–°æ–‡ä»¶ï¼Œåº”è¯¥é©±é€ä½é¢‘æ–‡ä»¶ï¼Œä¿ç•™é«˜é¢‘å’Œæ¨¡å¼æ–‡ä»¶
        for file_path in test_files[20:]:
            cache.get_file_lines(file_path)

        # éªŒè¯æ™ºèƒ½LRUç­–ç•¥
        stats = cache.get_cache_stats()
        print(f"   æœ€ç»ˆæ–‡ä»¶æ•°: {stats['file_count']}")
        print(f"   æ¸…ç†æ¬¡æ•°: {stats['cleanup_count']}")

        # æ£€æŸ¥é«˜é¢‘æ–‡ä»¶æ˜¯å¦ä»åœ¨ç¼“å­˜ä¸­
        high_freq_preserved = 0
        for file_path in high_freq_files:
            if file_path in cache._cache:
                high_freq_preserved += 1

        print(f"   é«˜é¢‘æ–‡ä»¶ä¿ç•™: {high_freq_preserved}/{len(high_freq_files)}")

        # éªŒè¯ç­–ç•¥æ•ˆæœ
        assert stats['file_count'] <= 20, "æ–‡ä»¶æ•°é‡æ§åˆ¶å¤±æ•ˆ"
        assert high_freq_preserved >= 3, "æ™ºèƒ½LRUç­–ç•¥æœªèƒ½ä¿æŠ¤é«˜é¢‘æ–‡ä»¶"

        print("âœ… æ™ºèƒ½LRUç­–ç•¥æµ‹è¯•é€šè¿‡!")
        return stats


def test_cache_statistics_monitoring():
    """æµ‹è¯•ç¼“å­˜ç»Ÿè®¡ç›‘æ§åŠŸèƒ½"""
    print("\nğŸ“Š æµ‹è¯•ç¼“å­˜ç»Ÿè®¡ç›‘æ§åŠŸèƒ½...")

    cache = OptimizedFileCache(max_size=50, max_memory_mb=3)

    with tempfile.TemporaryDirectory() as temp_dir:
        test_files = create_large_project_files(temp_dir, 60)

        # æ‰§è¡Œå„ç§æ“ä½œæ¥ç”Ÿæˆç»Ÿè®¡æ•°æ®
        print("   æ‰§è¡Œç¼“å­˜æ“ä½œ...")

        # å†·è®¿é—®
        for file_path in test_files[:30]:
            cache.get_file_lines(file_path)

        # çƒ­è®¿é—® (é‡å¤)
        for file_path in test_files[:15]:
            cache.get_file_lines(file_path)

        # è·å–è¯¦ç»†ç»Ÿè®¡
        stats = cache.get_cache_stats()

        print(f"   ğŸ“ˆ ç¼“å­˜ç»Ÿè®¡æŠ¥å‘Š:")
        print(f"      æ–‡ä»¶æ•°é‡: {stats['file_count']}")
        print(f"      å†…å­˜ä½¿ç”¨: {stats['memory_usage_mb']:.2f}MB")
        print(f"      ç¼“å­˜å‘½ä¸­ç‡: {stats['cache_hit_ratio']:.3f}")
        print(f"      æ€»è¯·æ±‚æ•°: {stats['total_requests']}")
        print(f"      ç¼“å­˜å‘½ä¸­: {stats['cache_hits']}")
        print(f"      ç¼“å­˜æœªå‘½ä¸­: {stats['cache_misses']}")
        print(f"      è¿è¡Œæ—¶é—´: {stats['uptime_hours']:.2f}å°æ—¶")
        print(f"      æ¯å°æ—¶è¯·æ±‚: {stats['avg_requests_per_hour']:.1f}")
        print(f"      å†…å­˜å‹åŠ›: {stats['memory_pressure']}")
        print(f"      ç³»ç»Ÿå†…å­˜: {stats['system_memory_mb']:.0f}MB")
        print(f"      å¯ç”¨å†…å­˜: {stats['system_available_mb']:.0f}MB")

        # éªŒè¯ç»Ÿè®¡æ•°æ®åˆç†æ€§
        assert stats['total_requests'] > 0, "æ€»è¯·æ±‚æ•°åº”è¯¥å¤§äº0"
        assert stats['cache_hits'] + stats['cache_misses'] == stats['total_requests'], "å‘½ä¸­æ•°æ®ä¸ä¸€è‡´"
        assert 0 <= stats['cache_hit_ratio'] <= 1, "å‘½ä¸­ç‡åº”è¯¥åœ¨0-1ä¹‹é—´"
        assert stats['memory_usage_mb'] > 0, "å†…å­˜ä½¿ç”¨åº”è¯¥å¤§äº0"

        # æ£€æŸ¥è®¿é—®æ¨¡å¼ç»Ÿè®¡
        if 'most_accessed_files' in stats:
            print(f"   ğŸ”¥ æœ€é«˜è®¿é—®æ–‡ä»¶æ•°: {len(stats['most_accessed_files'])}")

        if 'recent_activity' in stats:
            activity = stats['recent_activity']
            print(f"   âš¡ æœ€è¿‘æ´»åŠ¨: {activity['active_files_last_hour']} æ–‡ä»¶")
            print(f"   ğŸ¯ ç¼“å­˜æ•ˆç‡: {activity['cache_efficiency']}")

        print("âœ… ç¼“å­˜ç»Ÿè®¡ç›‘æ§æµ‹è¯•é€šè¿‡!")
        return stats


def test_phase1_performance_targets():
    """æµ‹è¯•Phase 1æ€§èƒ½ç›®æ ‡è¾¾æˆæƒ…å†µ"""
    print("\nğŸ¯ éªŒè¯Phase 1æ€§èƒ½ç›®æ ‡...")

    # æ¸…ç†å…¨å±€ç¼“å­˜
    clear_global_cache()

    with tempfile.TemporaryDirectory() as temp_dir:
        # åˆ›å»º1000ä¸ªæ–‡ä»¶çš„å¤§å‹é¡¹ç›®
        print("   åˆ›å»º1000æ–‡ä»¶çš„å¤§å‹é¡¹ç›®...")
        test_files = create_large_project_files(temp_dir, 1000)

        # è·å–å…¨å±€ç¼“å­˜ (ä½¿ç”¨æ™ºèƒ½å¤§å°)
        cache = get_file_cache()

        # è®°å½•å¼€å§‹æ—¶çš„å†…å­˜
        process = psutil.Process()
        start_memory = process.memory_info().rss / (1024 * 1024)  # MB

        print(f"   å¼€å§‹å†…å­˜ä½¿ç”¨: {start_memory:.1f}MB")

        # åŠ è½½æ‰€æœ‰æ–‡ä»¶ (æ¨¡æ‹Ÿå®é™…ä½¿ç”¨)
        print("   åŠ è½½æ–‡ä»¶ä¸­...")
        load_start = time.time()

        for i, file_path in enumerate(test_files):
            cache.get_file_lines(file_path)

            # æ¯100ä¸ªæ–‡ä»¶æ‰“å°è¿›åº¦
            if (i + 1) % 100 == 0:
                current_memory = process.memory_info().rss / (1024 * 1024)
                print(f"     è¿›åº¦: {i+1}/1000, å†…å­˜: {current_memory:.1f}MB")

        load_time = time.time() - load_start

        # è®°å½•ç»“æŸæ—¶çš„å†…å­˜
        end_memory = process.memory_info().rss / (1024 * 1024)
        cache_memory = end_memory - start_memory

        # è·å–è¯¦ç»†ç»Ÿè®¡
        stats = cache.get_cache_stats()

        print(f"\n   ğŸ“Š Phase 1 æ€§èƒ½ç»“æœ:")
        print(f"      æ€»åŠ è½½æ—¶é—´: {load_time:.2f}ç§’")
        print(f"      ç¼“å­˜æ–‡ä»¶æ•°: {stats['file_count']}")
        print(f"      ç¼“å­˜å†…å­˜ä½¿ç”¨: {stats['memory_usage_mb']:.1f}MB")
        print(f"      è¿›ç¨‹å†…å­˜å¢é•¿: {cache_memory:.1f}MB")
        print(f"      ç¼“å­˜å‘½ä¸­ç‡: {stats['cache_hit_ratio']:.3f}")
        print(f"      æ¸…ç†æ¬¡æ•°: {stats['cleanup_count']}")

        # éªŒè¯Phase 1ç›®æ ‡
        print(f"\n   ğŸ¯ ç›®æ ‡éªŒè¯:")

        # ç›®æ ‡1: å†…å­˜ä½¿ç”¨ < 100MB (1000æ–‡ä»¶)
        memory_target = cache_memory < 100
        print(f"      å†…å­˜ç›®æ ‡ (<100MB): {'âœ…' if memory_target else 'âŒ'} {cache_memory:.1f}MB")

        # ç›®æ ‡2: ç¼“å­˜å‘½ä¸­ç‡ > 70%
        hit_rate_target = stats['cache_hit_ratio'] > 0.7
        print(f"      å‘½ä¸­ç‡ç›®æ ‡ (>70%): {'âœ…' if hit_rate_target else 'âŒ'} {stats['cache_hit_ratio']:.1%}")

        # ç›®æ ‡3: æ— å†…å­˜æ³„æ¼ (åˆç†çš„å†…å­˜å¢é•¿)
        memory_leak_check = cache_memory < 200  # åˆç†ä¸Šé™
        print(f"      å†…å­˜æ³„æ¼æ£€æŸ¥ (<200MB): {'âœ…' if memory_leak_check else 'âŒ'} {cache_memory:.1f}MB")

        # ç›®æ ‡4: æ€§èƒ½åˆç† (å¹³å‡<1ms/æ–‡ä»¶)
        avg_time_per_file = (load_time / 1000) * 1000  # ms
        performance_target = avg_time_per_file < 1.0
        print(f"      æ€§èƒ½ç›®æ ‡ (<1ms/æ–‡ä»¶): {'âœ…' if performance_target else 'âŒ'} {avg_time_per_file:.2f}ms")

        # æ€»ä½“è¯„ä¼°
        all_targets_met = all([memory_target, hit_rate_target, memory_leak_check, performance_target])

        print(f"\n   ğŸ† Phase 1 æ€»ä½“è¯„ä¼°: {'âœ… å…¨éƒ¨è¾¾æ ‡' if all_targets_met else 'âŒ éƒ¨åˆ†æœªè¾¾æ ‡'}")

        return {
            'memory_usage_mb': cache_memory,
            'cache_hit_ratio': stats['cache_hit_ratio'],
            'load_time_seconds': load_time,
            'avg_time_per_file_ms': avg_time_per_file,
            'targets_met': all_targets_met,
            'detailed_stats': stats
        }


def main():
    """ä¸»æµ‹è¯•å…¥å£"""
    print("=" * 80)
    print("ğŸš€ Phase 1 å†…å­˜ç®¡ç†ä¼˜åŒ–éªŒè¯æµ‹è¯•")
    print("=" * 80)

    try:
        # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
        smart_sizing = test_smart_cache_sizing()
        memory_pressure = test_memory_pressure_detection()
        lru_strategy = test_intelligent_lru_strategy()
        cache_monitoring = test_cache_statistics_monitoring()
        performance_results = test_phase1_performance_targets()

        print("\n" + "=" * 80)
        print("ğŸ‰ Phase 1 ä¼˜åŒ–éªŒè¯å®Œæˆ!")
        print("=" * 80)

        # æ€»ç»“æŠ¥å‘Š
        print(f"\nğŸ“‹ Phase 1 ä¼˜åŒ–æ€»ç»“:")
        print(f"   æ™ºèƒ½ç¼“å­˜å¤§å°: âœ… è‡ªåŠ¨é€‚é…ç³»ç»Ÿå†…å­˜")
        print(f"   å†…å­˜å‹åŠ›æ£€æµ‹: âœ… è‡ªåŠ¨æ¸…ç†å’Œä¿æŠ¤")
        print(f"   æ™ºèƒ½LRUç­–ç•¥: âœ… è®¿é—®æ¨¡å¼æ„ŸçŸ¥")
        print(f"   ç¼“å­˜ç»Ÿè®¡ç›‘æ§: âœ… å®Œæ•´æ€§èƒ½æŒ‡æ ‡")
        print(f"   æ€§èƒ½ç›®æ ‡è¾¾æˆ: {'âœ…' if performance_results['targets_met'] else 'âŒ'}")

        if performance_results['targets_met']:
            print(f"\nğŸ† æ­å–œ! Phase 1 å†…å­˜ç®¡ç†ä¼˜åŒ–å…¨éƒ¨ç›®æ ‡è¾¾æˆ:")
            print(f"   â€¢ å†…å­˜ä½¿ç”¨: {performance_results['memory_usage_mb']:.1f}MB (ç›®æ ‡: <100MB)")
            print(f"   â€¢ ç¼“å­˜å‘½ä¸­ç‡: {performance_results['cache_hit_ratio']:.1%} (ç›®æ ‡: >70%)")
            print(f"   â€¢ å¹³å‡æ€§èƒ½: {performance_results['avg_time_per_file_ms']:.2f}ms/æ–‡ä»¶ (ç›®æ ‡: <1ms)")
            print(f"   â€¢ åŠ è½½æ—¶é—´: {performance_results['load_time_seconds']:.2f}ç§’/1000æ–‡ä»¶")

        return performance_results['targets_met']

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)