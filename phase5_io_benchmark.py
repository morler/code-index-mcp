#!/usr/bin/env python3
"""
Phase 5 I/O Performance Benchmark - Async File Operations Optimization

Linusé£æ ¼I/Oæ€§èƒ½æµ‹è¯• - éªŒè¯å¼‚æ­¥æ–‡ä»¶æ“ä½œå’Œå†…å­˜æ˜ å°„ä¼˜åŒ–æ•ˆæœ
"""

import sys
import time
import json
import asyncio
import tempfile
from pathlib import Path
from typing import Dict, List, Any, Optional

# ç¡®ä¿å¯ä»¥å¯¼å…¥é¡¹ç›®æ¨¡å—
sys.path.insert(0, str(Path(__file__).parent / "src"))

try:
    from core.io_optimizer import (
        AsyncFileReader, OptimizedDirectoryScanner,
        read_file_optimized, read_file_lines_optimized,
        get_async_file_reader, get_directory_scanner
    )
    from core.index import CodeIndex
    from core.builder import IndexBuilder
    _OPTIMIZER_AVAILABLE = True
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)


class Phase5IOBenchmark:
    """Phase 5 I/Oä¼˜åŒ–æ€§èƒ½åŸºå‡†æµ‹è¯•"""

    def __init__(self, test_project_path: str):
        self.test_path = Path(test_project_path)
        if not self.test_path.exists():
            raise ValueError(f"æµ‹è¯•é¡¹ç›®è·¯å¾„ä¸å­˜åœ¨: {test_project_path}")

        self.results = {}

    def run_all_benchmarks(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰Phase 5 I/OåŸºå‡†æµ‹è¯•"""
        print("ğŸš€ Phase 5 I/O Optimization Performance Benchmark")
        print("=" * 60)

        # æµ‹è¯•é¡ºåº: æ–‡ä»¶è¯»å– -> ç›®å½•æ‰«æ -> æ‰¹é‡æ“ä½œ -> å†…å­˜æ˜ å°„
        benchmarks = [
            ("file_read_performance", "æ–‡ä»¶è¯»å–æ€§èƒ½å¯¹æ¯”"),
            ("directory_scan_performance", "ç›®å½•æ‰«ææ€§èƒ½å¯¹æ¯”"),
            ("batch_file_operations", "æ‰¹é‡æ–‡ä»¶æ“ä½œæ€§èƒ½"),
            ("memory_mapping_performance", "å†…å­˜æ˜ å°„å¤§æ–‡ä»¶æ€§èƒ½"),
            ("async_vs_sync_comparison", "å¼‚æ­¥vsåŒæ­¥æ€§èƒ½å¯¹æ¯”"),
        ]

        for method_name, description in benchmarks:
            print(f"\nğŸ“Š {description}...")
            start_time = time.time()
            try:
                result = getattr(self, method_name)()
                self.results[method_name] = result
                print(f"  âœ… å®Œæˆ ({time.time() - start_time:.3f}s)")
            except Exception as e:
                print(f"  âŒ å¤±è´¥: {e}")
                self.results[method_name] = {"error": str(e)}

        self._print_summary()
        return self.results

    def file_read_performance(self) -> Dict[str, Any]:
        """æ–‡ä»¶è¯»å–æ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
        # æ‰¾åˆ°ä¸€äº›æµ‹è¯•æ–‡ä»¶
        test_files = []
        for ext in ['.py', '.js', '.ts', '.go', '.rs']:
            files = list(self.test_path.rglob(f'*{ext}'))[:5]  # æ¯ç§ç±»å‹5ä¸ªæ–‡ä»¶
            test_files.extend(files)

        if not test_files:
            return {"error": "æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•æ–‡ä»¶"}

        results = {
            "total_files": len(test_files),
            "traditional_read_time": 0,
            "optimized_read_time": 0,
            "improvement_factor": 0
        }

        # ä¼ ç»Ÿè¯»å–æ–¹å¼
        start_time = time.time()
        traditional_content = []
        for file_path in test_files:
            try:
                content = file_path.read_text(encoding='utf-8', errors='ignore')
                traditional_content.append(len(content))
            except Exception:
                continue
        results["traditional_read_time"] = time.time() - start_time

        # ä¼˜åŒ–è¯»å–æ–¹å¼
        start_time = time.time()
        optimized_content = []
        for file_path in test_files:
            try:
                content = read_file_optimized(file_path, encoding='utf-8')
                optimized_content.append(len(content))
            except Exception:
                continue
        results["optimized_read_time"] = time.time() - start_time

        # è®¡ç®—æ”¹è¿›å€æ•°
        if results["optimized_read_time"] > 0:
            results["improvement_factor"] = results["traditional_read_time"] / results["optimized_read_time"]

        return results

    def directory_scan_performance(self) -> Dict[str, Any]:
        """ç›®å½•æ‰«ææ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
        results = {
            "traditional_scan_time": 0,
            "optimized_scan_time": 0,
            "improvement_factor": 0,
            "files_found": 0
        }

        # æ”¯æŒçš„æ‰©å±•å
        supported_extensions = {'.py', '.js', '.ts', '.go', '.rs', '.java', '.cpp', '.c', '.h'}
        skip_dirs = {'.venv', '__pycache__', '.git', 'node_modules', 'target', 'build'}

        # ä¼ ç»Ÿæ‰«ææ–¹å¼ (åŒæ­¥é€’å½’)
        def traditional_scan(base_path: Path) -> List[str]:
            files = []
            try:
                for item in base_path.rglob('*'):
                    if item.is_file() and item.suffix.lower() in supported_extensions:
                        # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤ç›®å½•ä¸­
                        if not any(skip_dir in item.parts for skip_dir in skip_dirs):
                            files.append(str(item))
            except Exception:
                pass
            return files

        start_time = time.time()
        traditional_files = traditional_scan(self.test_path)
        results["traditional_scan_time"] = time.time() - start_time
        results["files_found"] = len(traditional_files)

        # ä¼˜åŒ–æ‰«ææ–¹å¼ (å¼‚æ­¥å¹¶è¡Œ)
        async def optimized_scan():
            scanner = get_directory_scanner()
            return await scanner.scan_directory_async(
                self.test_path, supported_extensions, skip_dirs
            )

        start_time = time.time()
        try:
            optimized_files = asyncio.run(optimized_scan())
            results["optimized_scan_time"] = time.time() - start_time

            # è®¡ç®—æ”¹è¿›å€æ•°
            if results["optimized_scan_time"] > 0:
                results["improvement_factor"] = results["traditional_scan_time"] / results["optimized_scan_time"]
        except Exception as e:
            results["optimized_scan_error"] = str(e)

        return results

    def batch_file_operations(self) -> Dict[str, Any]:
        """æ‰¹é‡æ–‡ä»¶æ“ä½œæ€§èƒ½æµ‹è¯•"""
        # è·å–æµ‹è¯•æ–‡ä»¶åˆ—è¡¨
        test_files = list(self.test_path.rglob('*.py'))[:10]  # å–10ä¸ªPythonæ–‡ä»¶

        if len(test_files) < 3:
            return {"error": "æµ‹è¯•æ–‡ä»¶æ•°é‡ä¸è¶³"}

        results = {
            "file_count": len(test_files),
            "sequential_read_time": 0,
            "batch_read_time": 0,
            "improvement_factor": 0
        }

        # é¡ºåºè¯»å–
        start_time = time.time()
        sequential_results = []
        for file_path in test_files:
            try:
                content = read_file_optimized(file_path)
                sequential_results.append(len(content))
            except Exception:
                continue
        results["sequential_read_time"] = time.time() - start_time

        # æ‰¹é‡å¼‚æ­¥è¯»å–
        async def batch_read():
            reader = get_async_file_reader()
            return await reader.batch_read_files(test_files)

        start_time = time.time()
        try:
            batch_results = asyncio.run(batch_read())
            results["batch_read_time"] = time.time() - start_time

            # è®¡ç®—æ”¹è¿›å€æ•°
            if results["batch_read_time"] > 0:
                results["improvement_factor"] = results["sequential_read_time"] / results["batch_read_time"]
        except Exception as e:
            results["batch_read_error"] = str(e)

        return results

    def memory_mapping_performance(self) -> Dict[str, Any]:
        """å†…å­˜æ˜ å°„å¤§æ–‡ä»¶æ€§èƒ½æµ‹è¯•"""
        results = {
            "large_file_created": False,
            "traditional_read_time": 0,
            "mmap_read_time": 0,
            "improvement_factor": 0,
            "file_size_mb": 0
        }

        # åˆ›å»ºå¤§æ–‡ä»¶ç”¨äºæµ‹è¯• (5MB)
        test_content = "x" * 1024 * 1024 * 5  # 5MBçš„å†…å®¹

        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
            f.write(test_content)
            large_file_path = Path(f.name)

        try:
            results["large_file_created"] = True
            results["file_size_mb"] = large_file_path.stat().st_size / (1024 * 1024)

            # ä¼ ç»Ÿè¯»å–
            start_time = time.time()
            traditional_content = large_file_path.read_text(encoding='utf-8')
            results["traditional_read_time"] = time.time() - start_time

            # ä¼˜åŒ–è¯»å– (ä¼šè‡ªåŠ¨ä½¿ç”¨å†…å­˜æ˜ å°„)
            start_time = time.time()
            optimized_content = read_file_optimized(large_file_path)
            results["mmap_read_time"] = time.time() - start_time

            # éªŒè¯å†…å®¹ä¸€è‡´æ€§
            if len(traditional_content) == len(optimized_content):
                results["content_match"] = True

            # è®¡ç®—æ”¹è¿›å€æ•°
            if results["mmap_read_time"] > 0:
                results["improvement_factor"] = results["traditional_read_time"] / results["mmap_read_time"]

        finally:
            # æ¸…ç†æµ‹è¯•æ–‡ä»¶
            try:
                large_file_path.unlink()
            except Exception:
                pass

        return results

    def async_vs_sync_comparison(self) -> Dict[str, Any]:
        """å¼‚æ­¥vsåŒæ­¥æ€§èƒ½å…¨é¢å¯¹æ¯”"""
        # è·å–ä¸€ç»„æµ‹è¯•æ–‡ä»¶
        test_files = list(self.test_path.rglob('*.py'))[:20]

        if len(test_files) < 5:
            return {"error": "æµ‹è¯•æ–‡ä»¶æ•°é‡ä¸è¶³"}

        results = {
            "file_count": len(test_files),
            "sync_total_time": 0,
            "async_total_time": 0,
            "improvement_factor": 0
        }

        # åŒæ­¥æ–¹å¼
        start_time = time.time()
        sync_contents = []
        for file_path in test_files:
            try:
                content = file_path.read_text(encoding='utf-8', errors='ignore')
                sync_contents.append(len(content))
            except Exception:
                continue
        results["sync_total_time"] = time.time() - start_time

        # å¼‚æ­¥æ–¹å¼
        async def async_read_all():
            reader = get_async_file_reader()
            tasks = []
            for file_path in test_files:
                task = reader.read_file_async(file_path)
                tasks.append(task)

            contents = await asyncio.gather(*tasks, return_exceptions=True)
            return [len(c) for c in contents if isinstance(c, str)]

        start_time = time.time()
        try:
            async_contents = asyncio.run(async_read_all())
            results["async_total_time"] = time.time() - start_time

            # è®¡ç®—æ”¹è¿›å€æ•°
            if results["async_total_time"] > 0:
                results["improvement_factor"] = results["sync_total_time"] / results["async_total_time"]
        except Exception as e:
            results["async_error"] = str(e)

        return results

    def _print_summary(self):
        """æ‰“å°æ€§èƒ½æµ‹è¯•æ€»ç»“"""
        print("\n" + "=" * 60)
        print("ğŸ“ˆ Phase 5 I/O Optimization Performance Report")
        print("=" * 60)

        print("\nğŸš€ æ ¸å¿ƒI/Oæ€§èƒ½æŒ‡æ ‡:")

        # æ–‡ä»¶è¯»å–æ€§èƒ½
        if "file_read_performance" in self.results:
            result = self.results["file_read_performance"]
            if "improvement_factor" in result:
                factor = result["improvement_factor"]
                status = "âœ…" if factor > 1.0 else "âŒ"
                print(f"   æ–‡ä»¶è¯»å–ä¼˜åŒ–: {factor:.2f}x {status}")

        # ç›®å½•æ‰«ææ€§èƒ½
        if "directory_scan_performance" in self.results:
            result = self.results["directory_scan_performance"]
            if "improvement_factor" in result:
                factor = result["improvement_factor"]
                status = "âœ…" if factor > 1.0 else "âŒ"
                print(f"   ç›®å½•æ‰«æä¼˜åŒ–: {factor:.2f}x {status}")

        # æ‰¹é‡æ“ä½œæ€§èƒ½
        if "batch_file_operations" in self.results:
            result = self.results["batch_file_operations"]
            if "improvement_factor" in result:
                factor = result["improvement_factor"]
                status = "âœ…" if factor > 1.0 else "âŒ"
                print(f"   æ‰¹é‡æ“ä½œä¼˜åŒ–: {factor:.2f}x {status}")

        # å†…å­˜æ˜ å°„æ€§èƒ½
        if "memory_mapping_performance" in self.results:
            result = self.results["memory_mapping_performance"]
            if "improvement_factor" in result:
                factor = result["improvement_factor"]
                status = "âœ…" if factor > 1.0 else "âŒ"
                print(f"   å¤§æ–‡ä»¶è¯»å–ä¼˜åŒ–: {factor:.2f}x {status}")

        # å¼‚æ­¥vsåŒæ­¥
        if "async_vs_sync_comparison" in self.results:
            result = self.results["async_vs_sync_comparison"]
            if "improvement_factor" in result:
                factor = result["improvement_factor"]
                status = "âœ…" if factor > 1.0 else "âŒ"
                print(f"   å¼‚æ­¥å¹¶å‘ä¼˜åŒ–: {factor:.2f}x {status}")

        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_file = "phase5_io_performance_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

        print("\nğŸ¯ Phase 5 Success Criteria Evaluation:")
        print("----------------------------------------")

        # æ ¹æ®plans.mdä¸­çš„ç›®æ ‡è¯„ä¼°
        overall_success = True

        # æ–‡ä»¶æ“ä½œ < 0.1ms for cached files
        if "file_read_performance" in self.results:
            result = self.results["file_read_performance"]
            if "optimized_read_time" in result and "total_files" in result:
                avg_time_per_file = (result["optimized_read_time"] / result["total_files"]) * 1000
                if avg_time_per_file < 0.1:
                    print(f"   æ–‡ä»¶æ“ä½œ < 0.1ms: âœ… é€šè¿‡ ({avg_time_per_file:.3f}ms)")
                else:
                    print(f"   æ–‡ä»¶æ“ä½œ < 0.1ms: âŒ æœªè¾¾æ ‡ ({avg_time_per_file:.3f}ms)")
                    overall_success = False

        # ç›®å½•æ‰«æ 2x faster
        if "directory_scan_performance" in self.results:
            result = self.results["directory_scan_performance"]
            if "improvement_factor" in result:
                factor = result["improvement_factor"]
                if factor >= 2.0:
                    print(f"   ç›®å½•æ‰«æ2xåŠ é€Ÿ: âœ… é€šè¿‡ ({factor:.2f}x)")
                else:
                    print(f"   ç›®å½•æ‰«æ2xåŠ é€Ÿ: âŒ æœªè¾¾æ ‡ ({factor:.2f}x)")
                    overall_success = False

        # æ— I/Oé˜»å¡
        if "async_vs_sync_comparison" in self.results:
            result = self.results["async_vs_sync_comparison"]
            if "improvement_factor" in result:
                factor = result["improvement_factor"]
                if factor > 1.0:
                    print(f"   å¼‚æ­¥éé˜»å¡I/O: âœ… é€šè¿‡ ({factor:.2f}x)")
                else:
                    print(f"   å¼‚æ­¥éé˜»å¡I/O: âŒ æœªè¾¾æ ‡ ({factor:.2f}x)")
                    overall_success = False

        if overall_success:
            print("\nâœ… Phase 5 æ‰€æœ‰ç›®æ ‡è¾¾æˆ!")
        else:
            print("\nâš ï¸  Phase 5 éƒ¨åˆ†ç›®æ ‡æœªè¾¾æˆ")

        print("\nâœ… Phase 5 I/Oä¼˜åŒ–åŸºå‡†æµ‹è¯•å®Œæˆ!")


def main():
    """ä¸»å‡½æ•°"""
    import sys

    # ä½¿ç”¨å½“å‰é¡¹ç›®ä½œä¸ºæµ‹è¯•ç›®æ ‡
    test_project = str(Path(__file__).parent)

    try:
        benchmark = Phase5IOBenchmark(test_project)
        benchmark.run_all_benchmarks()
    except Exception as e:
        print(f"âŒ åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()